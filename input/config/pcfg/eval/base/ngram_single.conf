# Config for eval.py
# Uses a trained model to evaluate all sequences in all partitions of the data.
# Use one of the scripts that inherits from this
# This evaluation combines the ngram tagger with the pcfg parser.

# Must be included in another file
# The inheriting file should define model_name, tagger_model_name and suffix
%% ABSTRACT

# Input sequence: select a single one from the db file
file           = %{PROJECT_ROOT}/input/fullseqs
filetype       = db
file-options   = index=%{sequence}

supertagger     = ngram-multi
# Increase the tagger beam with over the default
tagger-options  = batch=0.1:model=%{tagger_model_name}:partition=%{partition}

# Use the pcfg parser
parser      = pcfg
# Stop after 3h if we've not found anything
# Set quite a tight beam, so we can get a result in the time
parser-options = model=%{model_name}:partition=%{partition}:\
                 timeout=180:threshold=0.05:maxarc=15

# Output parse results to a file
output      = %{PROJECT_ROOT}/etc/output/pcfg/single/%{model_name}/%{tagger_model_name}/
# Output progress info to a file
logger      = %{PROJECT_ROOT}/etc/tmp/pcfg/single/%{model_name}/%{tagger_model_name}/
